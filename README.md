# Scraping Application / Server
https://github.com/daniel-mar/full_stack_scrape/assets/33047490/8be46d25-f4ba-4d48-bf5b-30b428395e23

## Full Stack ready application using:
- Python3, Flask, BootstrapJS, Libraries: [ Requests, Beautiful Soup:BS4 ]

Used to display scraping agent live on my dashboard.
## Features:
- Video demonstration comparing my table to live website
- Targets styling after confirming data served from Network tab
- Cleaning data and organized columns for .CSV file exporting and building table
- Flask Web Framework serving data with Jinja to my table.
- Table built in BootstrapJs

# Background: 
I was interested in how people scraped products off of websites and repurposed them. While making full stack crud Python flask applications with SQL, with login pages.
Had the idea that I could add my web scraping script after I had cleaned the data and had saved it to a .CSV file. Because the columns were great on excel in a earlier iteration of the script. I build out the web server and used the data on my web server, being careful to avoid refreshing too often in testing.

To add, I had wanted to achieve this because before I had use the PapaParseJs framework to view .CSV files while I was learning Data Analytics.
The collecting of data, cleaning and setting up the table for viewing was similar to what I was using the framework for except for static .CSV files.
I mention that because this data was first stored as a .CSV file prior to making it a web server.


## Disclaimer: This application requests on reload of webpage
## I am not responsible for the amount of requests you make from cloning this repository and using the web server.
## Any amount of refreshes that you make, is solely your responsibility.
